{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d5939c-4f39-4c61-bd49-ae690b412374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import sys\n",
    "import openai\n",
    "import speech_recognition as sr\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import cv2\n",
    "from vosk import KaldiRecognizer, SetLogLevel\n",
    "from vosk import Model as vosk_Model\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import json\n",
    "from Img_Mover.Img_Mover import Img_Mover\n",
    "from Girlfriend_Obj import Girlfriend_Obj\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess\n",
    "import gradio as gr\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import asyncio\n",
    "import threading\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03df0bb9-e3d7-4ccc-b7f4-2b01a399d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the custom audio model\n",
    "# audio_model_path = \"Audio_Generation/Generation_Scripts/saved_models/default\"\n",
    "\n",
    "# # Path to the custom audio data\n",
    "# audio_data_path = \"Audio_Generation/Generation_Scripts/data/albedo\"\n",
    "\n",
    "# Path to the custom model to load in\n",
    "custom_model_path = \"CustomModel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af919ccc-e80a-4bb5-972c-cf7839aa2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial summary is initially a basic prompt telling GPT-3 who it is\n",
    "initial_summ = \"You are my female waifu girlfriend who loves me.\"\n",
    "# The initial prompt tells GPT-3 how to respond\n",
    "initial_prompt = \"Me: Hi\\nYou: Hello\\n\\n\"\\\n",
    "    \"Me: How are you?\\nYou: Good. How are you?\\n\\n\"\\\n",
    "    \"Me: I'm good.\\nYou: Nice to meet you.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff61892-4280-46a4-a0fc-b9ed63744e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing image model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0190a17f43a34ed8b75672a1bd977e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image model initialized!\n",
      "Initializing custom text model\n",
      "Custom text model initialized!\n",
      "Initializing summarizer...\n",
      "Summarizer initialized!\n",
      "Not loading custom audio model\n",
      "Initializing custom image movement module\n",
      "Image movement module initialized!\n"
     ]
    }
   ],
   "source": [
    "# Setup function to setup the environment\n",
    "# memory_file = \"config_file.json\"\n",
    "memory_file = None\n",
    "MyGirlfriend = Girlfriend_Obj(initial_summ, initial_prompt, False, custom_model_path=custom_model_path, saved_memory=memory_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9b996-8fa0-4982-8053-c4b39a576a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77dd0bcd-a26b-4ca8-8aae-74a755c6f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device must be cuda\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31da8c-58d0-4aa2-aabc-a25d3d2472a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Used to declare whether movement should be added to the image or not from anywhere\n",
    "global add_movement\n",
    "add_movement = True\n",
    "\n",
    "# Sometimes the image should be forced to be regenerated, this\n",
    "# flag causes the image to be forced to regenerate once\n",
    "global force_gen\n",
    "force_gen = False\n",
    "\n",
    "\n",
    "def audio_auto_submit(custom_audio, custom_model, text, audio_pth, GPT_key):\n",
    "    if audio_pth != None:\n",
    "        return MyGirlfriend.generate_audio(custom_audio, custom_model, text, audio_pth, GPT_key)\n",
    "    global last_text\n",
    "    return last_text\n",
    "\n",
    "# Initialize the audio mixer\n",
    "mixer.init()\n",
    "mixer.music.unload()\n",
    "    \n",
    "# Handle changes to the motion switch which either turns on or\n",
    "# off image motion\n",
    "def handle_motion_switch(switch_value):\n",
    "    MyGirlfriend.add_movement = switch_value\n",
    "    \n",
    "    # Ensure the image is in the default position\n",
    "    MyGirlfriend.img_anim.pose *= 0\n",
    "        \n",
    "    # Force a reload in the image\n",
    "    MyGirlfriend.force_gen = True\n",
    "    \n",
    "# Handles file uploads\n",
    "def upload_file(file):\n",
    "    global last_image\n",
    "    global img_anim\n",
    "    global add_movement\n",
    "    global force_gen\n",
    "    \n",
    "    # Load the image as a PIL object\n",
    "    image = Image.open(file.name)\n",
    "    \n",
    "    # When an image is generated, load it in the animator\n",
    "    old_add_movement = MyGirlfriend.add_movement\n",
    "    MyGirlfriend.add_movement = False\n",
    "    MyGirlfriend.img_anim.load_new_image(img=image)\n",
    "    MyGirlfriend.add_movement = old_add_movement\n",
    "    \n",
    "    # Save the image in case of errors\n",
    "    MyGirlfriend.last_image = image\n",
    "    \n",
    "    # Ensure the image style vector is reset\n",
    "    MyGirlfriend.img_anim.pose *= 0\n",
    "    \n",
    "    # Force the image to be regenerated\n",
    "    MyGirlfriend.force_gen = True\n",
    "    \n",
    "    return file.name\n",
    "    \n",
    "# Handles image saving\n",
    "def save_img():\n",
    "    if not os.path.exists(\"saved_images\"):\n",
    "        os.mkdir(\"saved_images\")\n",
    "    filename = fr\"./saved_images/{time.ctime().replace(' ', '-').replace(':', '.')}.png\"\n",
    "    if type(MyGirlfriend.last_image) is not PIL.Image.Image:\n",
    "        Image.fromarray(MyGirlfriend.last_image.clip(0, 255).astype(np.uint8)).save(filename)\n",
    "    else:\n",
    "        MyGirlfriend.last_image.save(filename)\n",
    "        \n",
    "# Function used to test the mouth movement\n",
    "def test_mouth():\n",
    "    # Make sure the mouth isn't already moving\n",
    "    if MyGirlfriend.generating_mouth_movement == True:\n",
    "        return\n",
    "    \n",
    "    # Make sure the thread is not running\n",
    "    if MyGirlfriend.m_thread is not None:\n",
    "        MyGirlfriend.m_thread.join()\n",
    "    \n",
    "    # Start the mouth movement loop\n",
    "    MyGirlfriend.m_thread = threading.Thread(target=MyGirlfriend.run_talk_loop, args=(\"test_audio.mp3\",))\n",
    "    MyGirlfriend.m_thread.start()\n",
    "    \n",
    "\n",
    "interface = gr.Blocks()\n",
    "with interface:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Intro\"):\n",
    "            gr.Textbox(\"\"\"\n",
    "            Below is an intro explaining how this app works...\n",
    "            \n",
    "            Generation Tab:\n",
    "              Before starting, make sure to click the \"Setup interface\" button to\n",
    "              setup the inferface and to begin using the app.\n",
    "              \n",
    "              The upper-most part of the interface includes two tabs: \n",
    "              \"Voice-based Chat\" and \"Text-based Chat\" which are used\n",
    "              to repond to the AI. Voice-based allows you to use your\n",
    "              mic to talk to the AI while text-based allows you to\n",
    "              chat with the AI using text. The audio is auto-submitted\n",
    "              for response while the text requires either pressing the\n",
    "              \"enter\" key or clicking the \"Generate Audio\" button.\n",
    "              \n",
    "              The next part is the \"Response\" text field. The latest\n",
    "              response the AI gave will appear here.\n",
    "              \n",
    "              Below reponse is a section split into two parts. The left-most\n",
    "              part is the currently generated image. The rightmost section\n",
    "              has multiple parts:\n",
    "              1. \"Add motion to image?\" checkbox is used to toggle image\n",
    "                 animation. If checked, the image will be animated. The\n",
    "                 animation includes blinking and mouth movement assuming\n",
    "                 the image is in the correct form.\n",
    "              2. \"Mouth movement test\" can be used to check if mouth\n",
    "                 movement works for the current image.\n",
    "              3. \"Save current image\" saves the currently generated image\n",
    "                 to a folder named \"saved_images\". The filename will\n",
    "                 be the current time and date so that images don't\n",
    "                 overwrite eachother\n",
    "              4. \"Upload an image\" is used to upload an image you\n",
    "                 want to load in as opposed to generating one\n",
    "                 until one looks good. Clikcing on this button allows\n",
    "                 you to select the image you want to display.\n",
    "              \n",
    "              At the bottom of this section, there are two buttons:\n",
    "              \"Generate Audio\" and \"Generate Image\". \"Generate Audio\"\n",
    "              takes the currently entered text and generates a new\n",
    "              response from the AI. \"Generate Image\" is used to generate\n",
    "              a new image and display it.\n",
    "                 \n",
    "              Some notes about image animation:\n",
    "                The image must be in the correct form to be animated\n",
    "                correctly. The image should be a face-shot photo to\n",
    "                ensure that blinking is done correctly. Mouth movement\n",
    "                will occur if the image is face forward and when audio\n",
    "                is generated. Sometimes the mouth movement doesn't\n",
    "                work and if this is the case, you should probably\n",
    "                just generate an image until movement works.\n",
    "            \n",
    "            \n",
    "            Settings Tab:\n",
    "              The settings tab has several uses from loading in past memories\n",
    "              to changing the style of the image to generate.\n",
    "              \n",
    "              The first block in this tab is the \"Use custom chat model?\" checkbox.\n",
    "              If this box is checked, a free custom model will be used to\n",
    "              respond. Otherwise GPT-3 will respond. If the box is unchecked,\n",
    "              an OpenAI key is required which can obtained following this article:\n",
    "              https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0\n",
    "              If a key isn't provided, an error will be shown in place of\n",
    "              the response text.\n",
    "              \n",
    "              The next block is the \"Settings\" blocks which is used to setup\n",
    "              the style of the image and how it's generated. Settings can be\n",
    "              found at the following link (though do be warned, the site\n",
    "              has some sus images, not my doing btw):\n",
    "              https://danbooru.donmai.us/wiki_pages/tag_group:image_composition\n",
    "              \n",
    "              The next block is \"Characteristics\" which is also used to style\n",
    "              the generated images. These prompts are more of how you want the\n",
    "              generated image to look like. Should it be female or male?\n",
    "              What color hair?\n",
    "              \n",
    "              The \"settings\" block and \"characteristics\" block actually have no\n",
    "              difference when implemented, but it's nice to break up the\n",
    "              difference between image settings and image characteristics.\n",
    "              \n",
    "              The next block is the \"Guidance value\" which is used as a tradeoff\n",
    "              between Fidelity (how good the image looks) and variance (kind of how\n",
    "              creative the model is). A value of 1 is required, and having a\n",
    "              value too high will cause garbage to be produced. Keeping this\n",
    "              value around 10 seems to work well.\n",
    "              \n",
    "              The last part is a memory loading system. As the conversation goes on,\n",
    "              the conversation is saved to a memory file called \"config_file.json\". This\n",
    "              file can be loaded back in through this section of the settings to replace\n",
    "              the current conversation with a past one saved in a .json file.\n",
    "              ...\n",
    "              ...\n",
    "              ...\n",
    "              \n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.TabItem(\"Generation\"):\n",
    "            gen_col = gr.Column(visible=False)\n",
    "            with gen_col:\n",
    "                # Talking to the AI\n",
    "                with gr.Tabs():\n",
    "                    with gr.TabItem(\"Voice-based Chat\"):\n",
    "                        audio = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Response\", live=True)\n",
    "                    with gr.TabItem(\"Text-based Chat\"):\n",
    "                        text = gr.Textbox(label=\"Text\", value=\"I love you!\", interactive=True)\n",
    "                response = gr.Textbox(label=\"Response\", value=\"\", interactive=False)\n",
    "\n",
    "                with gr.Row():\n",
    "                    # Note gallery expects a 3-D array: (L, W, 3)\n",
    "                    gallery = gr.Image(label=\"Generated images\", show_label=False)\\\n",
    "                        .style(height=512)\n",
    "\n",
    "                    with gr.Column():\n",
    "                        # Switch to generate a new image with audio or keep the\n",
    "                        # image static\n",
    "                        motion_switch = gr.Checkbox(value=True, label=\"Add motion to image?\")\n",
    "                        motion_switch.change(fn=handle_motion_switch, inputs=[motion_switch], outputs=[])\n",
    "\n",
    "                        # Button to test mouth movement\n",
    "                        btn_mouth_test = gr.Button(\"Mouth movement test\")\n",
    "                        btn_mouth_test.click(fn=test_mouth, inputs=[], outputs=[])\n",
    "\n",
    "                        # Button to save the currently generated image\n",
    "                        btn_save_img = gr.Button(\"Save Current Image\")\n",
    "                        btn_save_img.click(fn=save_img, inputs=[], outputs=[])\n",
    "\n",
    "                        # Button to load an image\n",
    "                        upload_button = gr.UploadButton(\"Upload an image\", file_types=[\"image\"], file_count=\"single\")\n",
    "                        upload_button.upload(fn=upload_file, inputs=[upload_button])\n",
    "\n",
    "                with gr.Row():\n",
    "                    # Button to generate new audio\n",
    "                    btn_audio = gr.Button(\"Generate Audio\")\n",
    "\n",
    "                    # Button to generate new audio\n",
    "                    btn_img = gr.Button(\"Generate Image\")\n",
    "            \n",
    "            # Button to load and setup the generation tab\n",
    "            btn_load = gr.Button(\"Setup interface\")\n",
    "            btn_load.click(fn=MyGirlfriend.event_loop, inputs=[], outputs=[gallery, gen_col, btn_load], queue=True)\n",
    "            \n",
    "            \n",
    "        with gr.TabItem(\"Settings\"):\n",
    "            # Switched for which model to use\n",
    "            custom_model = gr.Checkbox(value=True, label=\"Use custom chat model? (False to use GPT, True to use custom model)\")\n",
    "            GPT_key_ = gr.Textbox(label=\"Key to use GPT-3 (if using GPT-3)\\nNote: If you don't have one go here: https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0\", value=\"\", interactive=True)\n",
    "            custom_audio = gr.Checkbox(value=False, label=\"Use custom audio model?\")\n",
    "\n",
    "            # Settings for the image\n",
    "            settings = gr.Textbox(label=\"Settings\", value= \"1girl,solo focus,very wide shot,feamle focus,ratio:16:9,detailed,looking at viewer,facing viewer,facing forward,vtuber\", interactive=True)\n",
    "            characteristics = gr.Textbox(label=\"Characteristics\", value=\"waifu,female,brown hair,blue eyes,sidelocks,slight blush,happy\", interactive=True)\n",
    "            guidance_scale = gr.Number(label=\"Guidance value - Tradeoff between creativity and image fidelity (greater than 1.0)\", value=10.0, interactive=True, precision=1)\n",
    "            \n",
    "            # Used to load a memory file\n",
    "            with gr.Column():\n",
    "                mem_file = gr.Textbox(label=\"Memory File\", value= \"\", interactive=True)\n",
    "                with gr.Row():\n",
    "                    mem_load_btn = gr.Button(\"Load memory file\")\n",
    "                    mem_file_success = gr.Textbox(label=\"Was the load successful?\", value= \"\", interactive=False)\n",
    "                    mem_load_btn.click(fn=MyGirlfriend.load_mem, inputs=[mem_file], outputs=[mem_file_success])\n",
    "            \n",
    "        # When the audio is changed, we want to auto submit it\n",
    "        audio.change(fn=audio_auto_submit, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        \n",
    "        # When the button or text is submitted, we want to generate new audio\n",
    "        btn_audio.click(fn=MyGirlfriend.generate_audio, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        text.submit(fn=MyGirlfriend.generate_audio, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        \n",
    "        # When the image button is clicked, we want to generate a new image\n",
    "        btn_img.click(fn=MyGirlfriend.generate_img, inputs=[settings, characteristics, guidance_scale], outputs=[])\n",
    "\n",
    "interface.queue(concurrency_count=2).launch(debug=True, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e689b-8407-4b0c-84c3-840c650efbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
