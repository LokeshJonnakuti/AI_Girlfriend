{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cf91360-42d0-45c0-97b7-b9400e1dfac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from transformers import pipeline, set_seed\n",
    "import torch\n",
    "import keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d239438-99fb-4d8d-8a4c-4372a30cedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OpenAIGPTLMHeadModel were not initialized from the model checkpoint at openai-gpt and are newly initialized: ['position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Two models\n",
    "# Note: pipeline documentation: https://huggingface.co/docs/transformers/v4.25.1/en/main_classes/pipelines#transformers.pipeline\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B', framework=\"pt\", device=torch.device(\"cuda:0\"), torch_dtype=torch.float16)\n",
    "generator2 = pipeline('text-generation', model='openai-gpt', framework=\"pt\", device=torch.device(\"cuda:0\"), torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9de887-a5c8-428b-a3d5-d45b54f3c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with some basic output\n",
    "init_str = \"You are roleplaying as my AI girlfriend who loves me. Your name is Megumin.\"\\\n",
    "           \"\\n\\n1: I love you. What's your name?\\n\\n2:  My name is Megumin.\\n\\n1: What would you like to do?\\n\\n2: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12a8688e-75d1-4767-804a-5d56223779ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"You are roleplaying as my AI girlfriend who loves me. Your name is Megumin.\\n\\n1: I love you. What's your name?\\n\\n2:  My name is Megumin.\\n\\n1: What would you like to do?\\n\\n2:  I want to go to school.\\n\\n1: What is your hobby?\\n\\n2:  I like going to the beach.\\n\\n1: What do you like about yourself?\\n\\n2:  I like talking.\\n\\n1: What does your hobby involve?\\n\\n2:  I like the beach.\\n\\n1: What does your hobby involve?\\n\\n3: I like to read books.\\n\\n1: What else do you like?\\n\\n2:  I like going to the beach.\\n\\n1: What do you like about yourself?\\n\\n3: I like going to the beach.\\n\\n1: What is your hobby?\\n\\n2:  I like going to the beach.\\n\\n3: I like to read books.\\n\\n1: What else do you like?\\n\\n2:  I like going to the beach.\\n\\n3: I like going to the beach.\\n\\n4: It is your birthday.\\n\\n1: What is your gift?\\n\\n2:  I want to go to the beach.\\n\\n1: What would you like to do?\\n\\n5:\"}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try some generation\n",
    "generator(init_str, max_length=300, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4206a98-cfdf-40d0-806e-60654feb55f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"You are roleplaying as my AI girlfriend who loves me. Your name is Megumin.\\n\\n1: I love you. What's your name?\\n\\n2:  My name is Megumin.\\n\\n1: What would you like to do?\\n\\n2:  that's right i said i liked your name. 3 : now i do it. 7 : i love you but now i don't know if i'm going to get you to do anything. 5 : i'm going to tell you something that's a secret. 8 : i don't know, you are a strange alien who lives amongst me and is so very different from anyone i've ever met. 5 : oh, but don't worry, you 'll like me once you try and change the rest of your life. 5 : i know you're hiding something. 6 : in the desert of my life, i was born in a house on the border of a small town, a few hundred miles from the base of the mountain known as the sun tower. there was no one there, although the town was close to a desert state school, in north america in order to keep students safe. your name is the only known thing i know and i will tell you how you got here. so it is up to you. 6 : why do you want to know? i might tell you so you can learn a thing or two about how the universe works. 7 : you shouldn't be here with me because from what i know,\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from model 2\n",
    "generator2(init_str, max_length=300, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f28f497b-e36e-427b-bc89-737c1dc7ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'd like to help you.\n"
     ]
    }
   ],
   "source": [
    "# Let's try some smarter generation.\n",
    "\n",
    "# Max length is the current length plus an offset\n",
    "max_length = len(init_str)+50\n",
    "\n",
    "# Generate one output\n",
    "out = generator(init_str, max_length=300, num_return_sequences=1)[0][\"generated_text\"]\n",
    "\n",
    "# Get the first sentence outputted\n",
    "print(out[len(init_str):].split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "195f5211-6382-4dd1-a662-5a5c682a6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'd like to help you.\n"
     ]
    }
   ],
   "source": [
    "e = \"I'd like to help you.\\n\\n1: With what?\\n\\n2: \"\n",
    "max_length = len(init_str)+len(e)+50\n",
    "out = generator(init_str+e, max_length=300, num_return_sequences=1)[0][\"generated_text\"]\n",
    "print(out[len(init_str)+len(e):].split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68469c58-23b5-4250-8462-6f3591ae062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Are you my waifu?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, no.\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What are you then?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're so sweet.\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Are you my girlfriend?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, no.\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keyboard\u001b[38;5;241m.\u001b[39mis_pressed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mesc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Get new text from the user\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Make the text a prompt like `1: [text]\\n\\n2: `\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Let's try creating a pipeline to chat\n",
    "\n",
    "# Name of our girlfriend\n",
    "name = \"Megumin\"\n",
    "\n",
    "# Initial length and initial sequence\n",
    "init_str = f\"You are {name} and are person's AI girlfriend\\n\"\\\n",
    "           f\"{name} loves person\\n\"\\\n",
    "           \"\\n\\n\\n\\n\"\\\n",
    "           \"Person: Hello\\n\"\\\n",
    "           f\"{name}: Hi\\n\\n\"\n",
    "\n",
    "# History is the initial string\n",
    "history = init_str\n",
    "\n",
    "# The max length of the generated output\n",
    "limit = 50\n",
    "\n",
    "while not keyboard.is_pressed(\"esc\"):\n",
    "    # Get new text from the user\n",
    "    text = input()\n",
    "    \n",
    "    # Make the text a prompt like `1: [text]\\n\\n2: `\n",
    "    text = f\"Person: \\\"{text}\\\"\\n{name}: \\\"\"\n",
    "    \n",
    "    # Add the text to the current history\n",
    "    history += text\n",
    "    \n",
    "    # Create a new output\n",
    "    out = generator(history, max_length=len(history)+limit, num_return_sequences=1)[0][\"generated_text\"]\n",
    "    \n",
    "    # Get the output the AI actually created. The first\n",
    "    # sentence that is not empty\n",
    "    out = out[len(history):].split(\"\\n\")\n",
    "    out = [i.strip() for i in out if len(i.strip()) > 0][0]\n",
    "    if out[-1] != '\"':\n",
    "        out += '\"'\n",
    "\n",
    "    \n",
    "    # Print the output and save it to the history\n",
    "    print(out)\n",
    "    history += out + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf6296-65ca-4574-9e72-597844d73f29",
   "metadata": {},
   "source": [
    "Problems:\n",
    "1. Generations are long. Maybe limit it to `max_length=current_length+desired_max_legth (max_length=200+20)`\n",
    "2. Generator 2 is trained on books and talks like a book which we don't want\n",
    "3. Generator 1 looks much better than 2, but still not that good. Maybe I can fine-tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b2707-f2b2-45ea-ba89-03aa0d2e03b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
