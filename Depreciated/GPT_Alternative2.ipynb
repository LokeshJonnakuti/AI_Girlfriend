{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff832680-d968-4f26-9775-0641b76a1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc39cae-d192-4753-a1d8-627be904b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the model\n",
    "test_model = pipeline('text-generation',model=\"Finetuning/outputs/checkpoint-12000/\",\n",
    "                      tokenizer='EleutherAI/gpt-neo-1.3B',max_new_tokens=50,\n",
    "                      torch_dtype=torch.float16,framework=\"pt\",\n",
    "                      device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2204bd2-8fbc-43bc-9aa4-bb5bc58b883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial prompt\n",
    "prompt = \"Hi\\nHello\\n\\n\"\\\n",
    "         \"How are you?\\nGood. How are you?\\n\\n\"\\\n",
    "         \"I'm good.\\nNice to meet you.\\n\\n\"\\\n",
    "\n",
    "prompt = \"The following is a conversation with me and my waifu girlfriend\\n\\n\"\\\n",
    "         \"Me: Hello\\nGirlfriend: Hello\\n\"\\\n",
    "         \"Me: How are you?\\nGirlfriend: I am good\\n\"\n",
    "         # \"Me: Do you like me?\\nGirlfriend: Yes I do.\\n\"\n",
    "\n",
    "# Number of prompt entered\n",
    "num_prompts = 0\n",
    "\n",
    "# Number of prompt until output can be extended\n",
    "num_till_exten = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ed4ae-3976-40e1-97f7-dd27762ed472",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # How many newlines are there?\n",
    "    num = prompt.count(\"\\n\")\n",
    "\n",
    "    # Get user input\n",
    "    print(\"Prompt: \", end=\"\")\n",
    "    text = input()\n",
    "\n",
    "    if text == \"\":\n",
    "        break\n",
    "\n",
    "    # Add the text to the current prompt\n",
    "    text = f\"Me: {text}\\n\"\n",
    "    prompt += text\n",
    "    num += 1\n",
    "\n",
    "    # Get the model output. at the correct position\n",
    "    output = test_model(prompt)[0]['generated_text'].replace(\"Girlfriend: \", \"\").split(\"\\n\")\n",
    "    output_new = output[num].strip()\n",
    "\n",
    "    # Make sure the output is not blank\n",
    "    tmp = 1\n",
    "    #output_new = output_new.replace(\"You:\", \"\").replace(\"Person:\", \"\")\n",
    "    while output_new == \"\":\n",
    "        output_new = output[num+tmp].strip()\n",
    "        tmp += 1\n",
    "        \n",
    "    # If the model is generating newlines after its text,\n",
    "    # it may want to say more\n",
    "    cur_out = output_new\n",
    "    if num_till_exten <= num_prompts:\n",
    "        more_max = 0 # Max limit on how much more to add\n",
    "        more_added = 0 # Current extra added\n",
    "        while more_added < more_max:\n",
    "            try:\n",
    "                if output[num+tmp].strip() == \"\":\n",
    "                    break # Break is a \\n\\n is reached. Keep going if only \\n\n",
    "                out_new = output[num+tmp].strip()\n",
    "                if out_new not in punctuation:\n",
    "                    out_new += \".\"\n",
    "                cur_out += f\" {out_new}\"\n",
    "                more_added += 1\n",
    "                tmp += 1\n",
    "\n",
    "                # If a question make was the last letter,\n",
    "                # stop adding more lines\n",
    "                if cur_out[-1] == \"?\":\n",
    "                    break\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "    # Print the output\n",
    "    #output_new = output_new.replace(\"You:\", \"\").replace(\"Person:\", \"\")\n",
    "    cur_out = cur_out.split(\":\")[0]\n",
    "    print(cur_out)\n",
    "\n",
    "    # Add the outputted text to the prompt\n",
    "    prompt += f\"Girlfriend: {cur_out.strip()}\\n\"\n",
    "    num_prompts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a66839-480c-4043-b725-dec6dc287064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
