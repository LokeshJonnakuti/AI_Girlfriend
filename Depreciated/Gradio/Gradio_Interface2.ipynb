{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8cd6ae-0b8d-4813-ae74-9b069d0b6ecf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\gabri\\anaconda3\\lib\\site-packages (3.16.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: pydub in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: altair>=4.2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (3.6.3)\n",
      "Requirement already satisfied: fastapi in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from gradio) (0.87.0)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from gradio) (2.28.2)\n",
      "Requirement already satisfied: orjson in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (3.8.5)\n",
      "Requirement already satisfied: markupsafe in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (3.16.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: websockets>=10.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (0.23.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (1.10.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (9.3.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gradio) (2022.10.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (4.16.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pandas->gradio) (2022.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: starlette==0.21.0 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from fastapi->gradio) (0.21.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from starlette==0.21.0->fastapi->gradio) (3.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx->gradio) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py~=1.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (4.37.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->gradio) (23.0)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from python-multipart->gradio) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from requests->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keybert in c:\\users\\gabri\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from keybert) (1.23.5)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from keybert) (2.2.2)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from keybert) (13.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from keybert) (1.2.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (2.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn>=0.22.2->keybert) (1.9.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.14.1+cu116)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.97)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (1.13.1+cu116)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.64.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (3.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.11.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.10.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabri\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\gabri\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0709b-424d-4ece-8e79-2f9889379281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579f060-0277-47a8-b091-be2b6264293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import sys\n",
    "import openai\n",
    "sys.path.append(\"../\")\n",
    "import speech_recognition as sr\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import cv2\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import json\n",
    "from Talking_Head.Talking_Head import Talking_Head\n",
    "from putting_it_together import blink_loop\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess\n",
    "import gradio as gr\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import asyncio\n",
    "import threading\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ed644-9a7d-4a69-a635-2683a52cb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from putting_it_together import WaifuObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a00ddd-4b9a-42f2-a60b-a783dc5933ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recognizer\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea45a20-aea6-4f7c-adb2-b41b57bd0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the custom audio model\n",
    "audio_model_path = \"../Audio_Generation/Generation_Scripts/saved_models/default\"\n",
    "\n",
    "# Path to the custom audio data\n",
    "audio_data_path = \"../Audio_Generation/Generation_Scripts/data/albedo\"\n",
    "\n",
    "# Path to the custom model to load in\n",
    "custom_model_path = \"../Finetuning/outputs/r/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce20bb3-e641-47c8-8070-df3e6f11dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial summary is initially a basic prompt telling GPT-3 who it is\n",
    "initial_summ = \"You are my female waifu girlfriend who loves me.\"\\\n",
    "# The initial prompt tells GPT-3 how to respond\n",
    "initial_prompt = \"Me: Hi\\nYou: Hello\\n\\n\"\\\n",
    "    \"Me: How are you?\\nYou: Good. How are you?\\n\\n\"\\\n",
    "    \"Me: I'm good.\\nYou: Nice to meet you.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7eb5c-0914-403d-bd9a-3a1e9cd63e33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing image model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563926cf2fd948e3a220e2626bbfc17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image model initialized!\n",
      "Initializing custom text model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">614</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">611 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">612 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">613 │   │   │   │   # Load from local folder or from cache or download from model Hub and ca</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>614 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>resolved_config_file = cached_file(                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">615 │   │   │   │   │   </span>pretrained_model_name_or_path,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">616 │   │   │   │   │   </span>configuration_file,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">617 │   │   │   │   │   </span>cache_dir=cache_dir,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">409</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 406 │   </span>user_agent = http_user_agent(user_agent)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 407 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 408 │   │   # Load from URL or cache if already cached</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 409 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>resolved_file = hf_hub_download(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 │   │   │   </span>path_or_repo_id,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 │   │   │   </span>filename,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 │   │   │   </span>subfolder=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(subfolder) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> subfolder,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_validators.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">114</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   </span>kwargs.items(),  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Kwargs values</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   │   </span>):                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> arg_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"repo_id\"</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>validate_repo_id(arg_value)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> arg_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> arg_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   │   │   </span>has_token = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_validators.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">172</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_repo_id</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> REPO_ID_REGEX.match(repo_id):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>172 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are\"</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" forbidden, '-' and '.' cannot start or end the name, max length is 96:\"</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" '{</span>repo_id<span style=\"color: #808000; text-decoration-color: #808000\">}'.\"</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">HFValidationError: </span>Repo id must use alphanumeric chars or <span style=\"color: #008000; text-decoration-color: #008000\">'-'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'_'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'--'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'..'</span> are forbidden, <span style=\"color: #008000; text-decoration-color: #008000\">'-'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span> \n",
       "cannot start or end the name, max length is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'CustomModel/'</span>.\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 # Setup function to setup the environment</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 # memory_file = \"config_file.json\"</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>memory_file = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4 Module = WaifuObj(initial_summ, initial_prompt, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, audio_model_path, audio_data_path     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\AI Stuff\\MyWaifu\\Depreciated\\Gradio\\..\\putting_it_together.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">149</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146 │   │   # https://huggingface.co/EleutherAI/gpt-neo-1.3B/</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 │   │   # Max len is 2048</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Initializing custom text model\"</span>)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>149 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.other_text_model = pipeline(<span style=\"color: #808000; text-decoration-color: #808000\">'text-generation'</span>,model=custom_model_path,        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 │   │   │   │   │   │   </span>tokenizer=<span style=\"color: #808000; text-decoration-color: #808000\">'EleutherAI/gpt-neo-1.3B'</span>,max_new_tokens=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">50</span>,             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 │   │   │   │   │   │   </span>torch_dtype=torch.float16,framework=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>,                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 │   │   │   │   │   │   </span>device=torch.device(<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda:0\"</span>),                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\__init__.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pipeline</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">642 │   │   </span>config = AutoConfig.from_pretrained(config, _from_pipeline=task, **hub_kwargs, *   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">643 │   │   </span>hub_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config._commit_hash                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">644 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> config <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(model, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs, **   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">646 │   │   </span>hub_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config._commit_hash                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">647 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">648 │   </span>custom_tasks = {}                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\auto\\configurat</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">ion_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">809</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">806 │   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_from_auto\"</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">807 │   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"name_or_path\"</span>] = pretrained_model_name_or_path                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">808 │   │   </span>trust_remote_code = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"trust_remote_code\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>809 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">810 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"auto_map\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"AutoConfig\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"auto_map\"</span>]:          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">811 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> trust_remote_code:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">812 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">559</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_config_dict</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">556 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">557 │   │   </span>original_kwargs = copy.deepcopy(kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">558 │   │   # Get config dict associated with the base config file</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>559 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_config_dict(pretrained_model_name_or_path, **kwar   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">560 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">561 │   │   │   </span>original_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>]                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">562 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">635</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">632 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">633 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">634 │   │   │   │   # For any other exception, we throw a generic error.</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>635 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">636 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Can't load the configuration of '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}'.</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">637 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" from 'https://huggingface.co/models', make sure you don't have a l</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">638 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" name. Otherwise, make sure '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}' is t</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>Can't load the configuration of <span style=\"color: #008000; text-decoration-color: #008000\">'CustomModel/'</span>. If you were trying to load it from \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/models'</span>, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure <span style=\"color: #008000; text-decoration-color: #008000\">'CustomModel/'</span> is the correct path to a directory containing a config.json file\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m614\u001b[0m in \u001b[92m_get_config_dict\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m611 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m612 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m613 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Load from local folder or from cache or download from model Hub and ca\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m614 \u001b[2m│   │   │   │   \u001b[0mresolved_config_file = cached_file(                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m615 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m616 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconfiguration_file,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m617 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcache_dir=cache_dir,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\hub.py\u001b[0m:\u001b[94m409\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcached_file\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 409 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_validators.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33my\u001b[0m:\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   │   │   \u001b[0mvalidate_repo_id(arg_value)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_validators.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33my\u001b[0m:\u001b[94m172\u001b[0m in \u001b[92mvalidate_repo_id\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m REPO_ID_REGEX.match(repo_id):                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m172 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must use alphanumeric chars or \u001b[0m\u001b[33m'\u001b[0m\u001b[33m-\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m_\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m--\u001b[0m\u001b[33m'\u001b[0m\u001b[33m and \u001b[0m\u001b[33m'\u001b[0m\u001b[33m..\u001b[0m\u001b[33m'\u001b[0m\u001b[33m are\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m forbidden, \u001b[0m\u001b[33m'\u001b[0m\u001b[33m-\u001b[0m\u001b[33m'\u001b[0m\u001b[33m and \u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m'\u001b[0m\u001b[33m cannot start or end the name, max length is 96:\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_id\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mHFValidationError: \u001b[0mRepo id must use alphanumeric chars or \u001b[32m'-'\u001b[0m, \u001b[32m'_'\u001b[0m, \u001b[32m'.'\u001b[0m, \u001b[32m'--'\u001b[0m and \u001b[32m'..'\u001b[0m are forbidden, \u001b[32m'-'\u001b[0m and \u001b[32m'.'\u001b[0m \n",
       "cannot start or end the name, max length is \u001b[1;36m96\u001b[0m: \u001b[32m'CustomModel/'\u001b[0m.\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[2m# Setup function to setup the environment\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m# memory_file = \"config_file.json\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0mmemory_file = \u001b[94mNone\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4 Module = WaifuObj(initial_summ, initial_prompt, \u001b[94mFalse\u001b[0m, audio_model_path, audio_data_path     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mD:\\AI Stuff\\MyWaifu\\Depreciated\\Gradio\\..\\putting_it_together.py\u001b[0m:\u001b[94m149\u001b[0m in \u001b[92m__init__\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# https://huggingface.co/EleutherAI/gpt-neo-1.3B/\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Max len is 2048\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mInitializing custom text model\u001b[0m\u001b[33m\"\u001b[0m)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m149 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.other_text_model = pipeline(\u001b[33m'\u001b[0m\u001b[33mtext-generation\u001b[0m\u001b[33m'\u001b[0m,model=custom_model_path,        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m150 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtokenizer=\u001b[33m'\u001b[0m\u001b[33mEleutherAI/gpt-neo-1.3B\u001b[0m\u001b[33m'\u001b[0m,max_new_tokens=\u001b[94m50\u001b[0m,             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtorch_dtype=torch.float16,framework=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m,                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mdevice=torch.device(\u001b[33m\"\u001b[0m\u001b[33mcuda:0\u001b[0m\u001b[33m\"\u001b[0m),                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m645\u001b[0m in \u001b[92mpipeline\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m642 \u001b[0m\u001b[2m│   │   \u001b[0mconfig = AutoConfig.from_pretrained(config, _from_pipeline=task, **hub_kwargs, *   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m643 \u001b[0m\u001b[2m│   │   \u001b[0mhub_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config._commit_hash                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m644 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m config \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[96misinstance\u001b[0m(model, \u001b[96mstr\u001b[0m):                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m645 \u001b[2m│   │   \u001b[0mconfig = AutoConfig.from_pretrained(model, _from_pipeline=task, **hub_kwargs, **   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m646 \u001b[0m\u001b[2m│   │   \u001b[0mhub_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config._commit_hash                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m647 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m648 \u001b[0m\u001b[2m│   \u001b[0mcustom_tasks = {}                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\auto\\configurat\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mion_auto.py\u001b[0m:\u001b[94m809\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m806 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_from_auto\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[94mTrue\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m807 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33mname_or_path\u001b[0m\u001b[33m\"\u001b[0m] = pretrained_model_name_or_path                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m808 \u001b[0m\u001b[2m│   │   \u001b[0mtrust_remote_code = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mtrust_remote_code\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m809 \u001b[2m│   │   \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m810 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mAutoConfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m]:          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m811 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m trust_remote_code:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m812 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m559\u001b[0m in \u001b[92mget_config_dict\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m556 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m557 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_kwargs = copy.deepcopy(kwargs)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m558 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Get config dict associated with the base config file\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m559 \u001b[2m│   │   \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m._get_config_dict(pretrained_model_name_or_path, **kwar   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m560 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m561 \u001b[0m\u001b[2m│   │   │   \u001b[0moriginal_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config_dict[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m562 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\gabri\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m635\u001b[0m in \u001b[92m_get_config_dict\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m632 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m633 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m634 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# For any other exception, we throw a generic error.\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m635 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m636 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCan\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt load the configuration of \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m637 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m from \u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/models\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, make sure you don\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt have a l\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m638 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m name. Otherwise, make sure \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is t\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0mCan't load the configuration of \u001b[32m'CustomModel/'\u001b[0m. If you were trying to load it from \n",
       "\u001b[32m'https://huggingface.co/models'\u001b[0m, make sure you don't have a local directory with the same name. Otherwise, make \n",
       "sure \u001b[32m'CustomModel/'\u001b[0m is the correct path to a directory containing a config.json file\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup function to setup the environment\n",
    "# memory_file = \"config_file.json\"\n",
    "memory_file = None\n",
    "Module = WaifuObj(initial_summ, initial_prompt, False, audio_model_path, audio_data_path, custom_model_path, memory_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f835610-7b1e-40d2-8eac-32f7ad0bc1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17204246-581a-4197-8806-08a8120cc125",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c3878-3c14-4db2-ada2-c69b6031e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the image\n",
    "# img = Image.open(\"test.png\")\n",
    "img = Image.open(\"../Talking_Head/data/illust/../../../test3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458ef763-6ceb-4f1d-9f0f-dd533531faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a global Talking Head class to store the global vector\n",
    "global img_anim\n",
    "img_anim = Talking_Head(torch.device(\"cuda:0\"), 0.5, automatic_EMA=True)\n",
    "\n",
    "# Load in the new image\n",
    "img_anim.load_new_image(img=deepcopy(img))\n",
    "\n",
    "# Default pose for the image\n",
    "img_anim.change_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73ef650-541c-49d5-b78e-34a254dbffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the word data from a mp3 file\n",
    "def extract_word_data(filename):\n",
    "    # Load in the model\n",
    "    model_path = \"../vosk_models/vosk-model-small-en-us-0.15\"\n",
    "    model = Model(model_path)\n",
    "    \n",
    "    # Make the audio a wav file\n",
    "    f = AudioSegment.from_mp3(\"tmp.mp3\")\n",
    "    f.export(\"tmp.wav\", format=\"wav\")\n",
    "    \n",
    "    # Read in the audio\n",
    "    with wave.open(\"tmp.wav\", \"rb\") as wf:\n",
    "        # Prepare the model for rekognition\n",
    "        rec = KaldiRecognizer(model, wf.getframerate())\n",
    "        rec.SetWords(True)\n",
    "\n",
    "        # get the list of JSON dictionaries\n",
    "        results = []\n",
    "        # recognize speech using vosk model\n",
    "        data = wf.readframes(wf.getnframes())\n",
    "        while len(data) > 0:\n",
    "            if rec.AcceptWaveform(data):\n",
    "                part_result = json.loads(rec.Result())\n",
    "                results.append(part_result)\n",
    "            data = wf.readframes(wf.getnframes())\n",
    "        part_result = json.loads(rec.FinalResult())\n",
    "        results.append(part_result)\n",
    "    \n",
    "    audio_trans = results[0][\"result\"]\n",
    "    \n",
    "    # Get the delay between each word\n",
    "    for i in range(1, len(audio_trans)):\n",
    "        audio_trans[i][\"delay\"] = audio_trans[i][\"start\"]-audio_trans[i-1][\"end\"]\n",
    "    audio_trans[0][\"delay\"] = audio_trans[0][\"start\"]\n",
    "    \n",
    "    return audio_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede06c3c-792e-4820-88d9-163f768fa21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literally all this function does is update the\n",
    "# eye part of the vector every so often\n",
    "global DONE\n",
    "DONE = False\n",
    "async def blink_loop():\n",
    "    global img_anim\n",
    "    \n",
    "    # We want to iterate forever\n",
    "    while not DONE:\n",
    "        # Wait a little to blink again\n",
    "        if img_anim.eye_cycle_end:\n",
    "            # Blink anywhere between 2 and 7 secods with\n",
    "            # a mean around 5 seconds (avg blink wait time)\n",
    "            t = np.clip(np.random.normal(5, 1, size=1)[0], 2, 7)\n",
    "\n",
    "            # Wait a little before blinking again\n",
    "            time.sleep(t)\n",
    "            img_anim.eye_cycle_end = False\n",
    "        \n",
    "        # Update the vector\n",
    "        img_anim.Move_eyes()\n",
    "        \n",
    "        # Wait for a new frame to be generated\n",
    "        while img_anim.eye_frame_disp == False:\n",
    "            time.sleep(0.001)\n",
    "\n",
    "# Used to make a thread running the blink loop\n",
    "def run_blink_loop():\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "    loop.run_until_complete(blink_loop())\n",
    "    loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc7296b-8984-4bb9-bb84-f19387c6b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def talk_loop(filename):\n",
    "    global img_anim\n",
    "    global generating_mouth_movement\n",
    "    \n",
    "    # Get the audio transcript\n",
    "    audio_trans = extract_word_data(filename)\n",
    "    \n",
    "    # Play the audio\n",
    "    mixer.init()\n",
    "    mixer.stop()\n",
    "    mixer.music.unload()\n",
    "    try:\n",
    "        mixer.music.load(filename)\n",
    "        mixer.music.play()\n",
    "    except pygame.error:\n",
    "        s = mixer.Sound(filename)\n",
    "        s.play()\n",
    "    \n",
    "    # Iterate over all parts of the audio transcription\n",
    "    for idx, part in enumerate(audio_trans):\n",
    "        # Get the beginning and end of the audio piece\n",
    "        start = part[\"start\"]\n",
    "        end = part[\"end\"]\n",
    "        delay = part[\"delay\"]\n",
    "        \n",
    "        # Wait for the next audio part according to the\n",
    "        # delay in the audio. This delay should also take\n",
    "        # into account the expected generation time of the\n",
    "        # image as the delay starts after the previous generation\n",
    "        if idx != 0:\n",
    "            delay = max(0, delay-img_anim.EMA)\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        # Get the entire audio clip length\n",
    "        length = end-start\n",
    "        \n",
    "        # Setup the mouth movement cycle\n",
    "        img_anim.setup_mouth_movement(length)\n",
    "        \n",
    "        # Mouth movement is being generated\n",
    "        generating_mouth_movement = True\n",
    "        \n",
    "        # Iterate until the movement is done for this part\n",
    "        while img_anim.mouth_cycle_end == False:\n",
    "            # Update the vector\n",
    "            img_anim.Move_mouth()\n",
    "            \n",
    "            # Wait for a new frame to be generated\n",
    "            while img_anim.mouth_frame_disp == False:\n",
    "                time.sleep(0.001)\n",
    "                \n",
    "        # Mouth movement is not being generated\n",
    "        generating_mouth_movement = False\n",
    "            \n",
    "#             # Change the pose and show the image\n",
    "#             img = img_anim.change_pose()\n",
    "            \n",
    "#             # End EMA timer and update EMA\n",
    "#             if timer_s != -1:\n",
    "#                 img_anim.update_EMA(time.time()-timer_s)\n",
    "            \n",
    "#             # Start timer for EMA\n",
    "#             timer_s = time.time()\n",
    "            \n",
    "#             yield img\n",
    "    \n",
    "    \n",
    "# Used to make a thread running the talk loop\n",
    "def run_talk_loop(filename):\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "    loop.run_until_complete(talk_loop(filename))\n",
    "    loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68add5f-1974-4ab5-a48e-abee4a7c0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the mouth movement being generated? This\n",
    "# is used to inform the event loop if the mouth is\n",
    "# moving or if just the eyes are moving\n",
    "global generating_mouth_movement\n",
    "generating_mouth_movement = False\n",
    "\n",
    "def event_loop():\n",
    "    global img_anim\n",
    "    global generating_mouth_movement\n",
    "    global add_movement\n",
    "    global force_gen\n",
    "    global last_image\n",
    "    \n",
    "    # Initial update to make everything visible\n",
    "    blank_upd = gr.update()\n",
    "    yield last_image, gr.update(visible=True),\\\n",
    "            gr.update(visible=False)\n",
    "    \n",
    "    # Quick calibration. Blink 10 times\n",
    "    # and calibrate the time it takes\n",
    "    # to show the image for the EMA\n",
    "    for i in range(0, 10):\n",
    "        s = time.time()\n",
    "        img_anim.eye_cycle_end = False\n",
    "        while img_anim.eye_cycle_end == False:\n",
    "            img_anim.Move_eyes()\n",
    "            img = img_anim.change_pose()\n",
    "            img_anim.update_EMA(time.time()-s)\n",
    "            s = time.time()\n",
    "            yield img, gr.update(), gr.update()\n",
    "    img_anim.eye_cycle_end = False\n",
    "    \n",
    "    # Start the blink loop\n",
    "    b_thread = threading.Thread(target=run_blink_loop, args=())\n",
    "    b_thread.start()\n",
    "    \n",
    "    while True:\n",
    "        # If the image is forced to be reloaded, generate\n",
    "        # the image and reset the flag\n",
    "        if force_gen == True:\n",
    "            img = img_anim.change_pose()\n",
    "            force_gen = False\n",
    "            yield img, gr.update(), gr.update()\n",
    "        \n",
    "        # If movement shouldn't be added, skip the loop\n",
    "        if add_movement == False:\n",
    "            time.sleep(0.0001)\n",
    "            continue\n",
    "        \n",
    "        # Wait until a new frame needs to be generated\n",
    "        if generating_mouth_movement == True:\n",
    "            if img_anim.mouth_frame_disp == False:\n",
    "                # Change the pose and show the image\n",
    "                img = img_anim.change_pose()\n",
    "\n",
    "                yield img, gr.update(), gr.update()\n",
    "        else:\n",
    "            # Start the mouth movement loop\n",
    "            # m_thread = threading.Thread(target=run_talk_loop, args=(\"tmp.mp3\",))\n",
    "            # m_thread.start()\n",
    "            # generating_mouth_movement = True\n",
    "            if img_anim.eye_frame_disp == False:\n",
    "                # Change the pose and show the image\n",
    "                img = img_anim.change_pose()\n",
    "\n",
    "                yield img, gr.update(), gr.update()\n",
    "        \n",
    "        time.sleep(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751b958-e1e9-4fb6-9a57-5c036a33364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# io = gr.Interface(event_loop, inputs=[], outputs=[gr.Image().style(height=330)])\n",
    "# io.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44560b-9a67-45b8-9eb9-f1d786ce5f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2176c-6d25-40f3-805e-e38ce729d51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba2d77-84c7-45d6-a188-e10ae7ef86d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 337, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 847, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\utils.py\", line 410, in async_iteration\n",
      "    return next(iterator)\n",
      "  File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_42252\\853872220.py\", line 27, in event_loop\n",
      "    img = img_anim.change_pose()\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Gradio\\..\\Talking_Head\\Talking_Head.py\", line 225, in change_pose\n",
      "    output_image = self.poser.pose(self.torch_input_image, self.pose)[0]\n",
      "AttributeError: 'Talking_Head' object has no attribute 'torch_input_image'\n"
     ]
    }
   ],
   "source": [
    "# Used to start and stop the mouth movement thread from anywhere\n",
    "global m_thread\n",
    "m_thread = None\n",
    "\n",
    "# Used to declare whether movement should be added to the image or not from anywhere\n",
    "global add_movement\n",
    "add_movement = True\n",
    "\n",
    "# Sometimes the image should be forced to be regenerated, this\n",
    "# flag causes the image to be forced to regenerate once\n",
    "global force_gen\n",
    "force_gen = False\n",
    "\n",
    "# Incase of an error, these can be used. These\n",
    "# globals are also used to reload stuff\n",
    "global last_image\n",
    "global last_text\n",
    "last_image = np.zeros((50, 50, 3))\n",
    "last_text = \"Error\"\n",
    "\n",
    "\n",
    "def build_img_prompt(text, settings, characteristics):\n",
    "    # Get the summary and sentiment\n",
    "    sent = get_sent(text)\n",
    "    summary = get_summ(text)\n",
    "    \n",
    "    # Create the image prompt\n",
    "    # settings = \"1girl, very wide shot, simple background, solo focus, female focus, looking at viewer, ratio:16:9, detailed\"\n",
    "    # characteristics = \"waifu, female, brown hair, blue eyes, sidelocks, slight blush, fox ears\"\n",
    "    # sent = \"furious\"\n",
    "    # summary = \"'I hope get know better' to viewer\"\n",
    "    img_prompt = f\"{settings} {characteristics} {','+sent if len(sent)!=0 else ''}, {summary}\"\n",
    "    return img_prompt\n",
    "\n",
    "\n",
    "def text_to_image(settings, characteristics, guidance_scale, text):\n",
    "    # Get the image prompt\n",
    "    img_prompt = Module.build_img_prompt(text, settings, characteristics)\n",
    "    \n",
    "    # Get the image\n",
    "    with Module.suppress_stdout():\n",
    "        with autocast(\"cuda\"):\n",
    "            image = Module.imgGen(img_prompt, guidance_scale=guidance_scale)[\"images\"]\n",
    "            \n",
    "    \n",
    "    return image\n",
    "\n",
    "# Overall function to generate text and audio\n",
    "def generate_audio(custom_audio, custom_model, text, audio_pth, GPT_key):\n",
    "    global prompt\n",
    "    global last_text\n",
    "    global generating_mouth_movement\n",
    "    global m_thread\n",
    "    if m_thread is not None:\n",
    "        m_thread.join()\n",
    "    \n",
    "    # Get the audio if there is any\n",
    "    if audio_pth:\n",
    "        # Open the wav file and read in the data\n",
    "        # Get the audio data\n",
    "        audio = sr.AudioFile(audio_pth)\n",
    "        with audio as source:\n",
    "            audio = r.record(source)\n",
    "        \n",
    "        text = audio_to_text(audio)\n",
    "    \n",
    "    # Add the text to the current prompt\n",
    "    Module.cur_prompt += f\"Me: {text}\\n\"\n",
    "    \n",
    "    # Get the response\n",
    "    if custom_model == True:\n",
    "        ret_text = Module.get_response()\n",
    "    else:\n",
    "        try:\n",
    "            ret_text = ret_text = Module.get_response(GPT_key)\n",
    "        except:\n",
    "            gr.Error(\"GPT key is either invalid or not given\")\n",
    "            return \"Error: GPT key is either invalid or not given.\"\n",
    "    \n",
    "    # Create audio and image for the returned text\n",
    "    if len(ret_text) > 3:\n",
    "        \n",
    "        # Create the audio clip\n",
    "        mixer.stop()\n",
    "        mixer.music.unload()\n",
    "        Module.create_audio(ret_text, custom_audio)\n",
    "        \n",
    "        # Start the mouth movement loop\n",
    "        m_thread = threading.Thread(target=run_talk_loop, args=(\"tmp.mp3\",))\n",
    "        m_thread.start()\n",
    "        \n",
    "        # Save the text in case of errors\n",
    "        last_text = ret_text\n",
    "        \n",
    "        return ret_text\n",
    "    \n",
    "\n",
    "    \n",
    "# Function used to generate images\n",
    "def generate_img(settings, characteristics, guidance_scale):\n",
    "    global last_image\n",
    "    global img_anim\n",
    "    global add_movement\n",
    "    global force_gen\n",
    "    \n",
    "    # Generate an image from the current prompt\n",
    "    ret_text = \"\"\n",
    "    image = text_to_image(settings, characteristics, guidance_scale, ret_text)[0]\n",
    "    \n",
    "    # When an image is generated, load it in the animator\n",
    "    old_add_movement = add_movement\n",
    "    add_movement = False\n",
    "    img_anim.load_new_image(img=image)\n",
    "    add_movement = old_add_movement\n",
    "    \n",
    "    # Save the image in case of errors\n",
    "    last_image = image\n",
    "    \n",
    "    # Ensure the image style vector is reset\n",
    "    img_anim.pose *= 0\n",
    "    \n",
    "    # Force the image to be regenerated\n",
    "    force_gen = True\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Transcribes audio to text\n",
    "def audio_to_text(audio):\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "    except sr.UnknownValueError:\n",
    "        text = \"\" # Default to nothing\n",
    "            \n",
    "    return text\n",
    "\n",
    "\n",
    "def audio_auto_submit(custom_audio, custom_model, text, audio_pth, GPT_key):\n",
    "    if audio_pth != None:\n",
    "        return generate_audio(custom_audio, custom_model, text, audio_pth, GPT_key)\n",
    "    global last_text\n",
    "    return last_text\n",
    "\n",
    "# Initialize the audio mixer\n",
    "mixer.init()\n",
    "mixer.music.unload()\n",
    "\n",
    "# Load in a memory file\n",
    "def load_mem(filename):\n",
    "    try:\n",
    "        Module.load_memory(filename)\n",
    "        return \"Success!\"\n",
    "    except:\n",
    "        return \"Fail! File does not exist or is in incorrect format\"\n",
    "    \n",
    "# Handle changes to the motion switch which either turns on or\n",
    "# off image motion\n",
    "def handle_motion_switch(switch_value):\n",
    "    global add_movement\n",
    "    global force_gen\n",
    "    add_movement = switch_value\n",
    "    \n",
    "    # Ensure the image is in the default position\n",
    "    img_anim.pose *= 0\n",
    "        \n",
    "    # Force a reload in the image\n",
    "    force_gen = True\n",
    "    \n",
    "# Handles file uploads\n",
    "def upload_file(file):\n",
    "    global last_image\n",
    "    global img_anim\n",
    "    global add_movement\n",
    "    global force_gen\n",
    "    \n",
    "    # Load the image as a PIL object\n",
    "    image = Image.open(file.name)\n",
    "    \n",
    "    # When an image is generated, load it in the animator\n",
    "    old_add_movement = add_movement\n",
    "    add_movement = False\n",
    "    img_anim.load_new_image(img=image)\n",
    "    add_movement = old_add_movement\n",
    "    \n",
    "    # Save the image in case of errors\n",
    "    last_image = image\n",
    "    \n",
    "    # Ensure the image style vector is reset\n",
    "    img_anim.pose *= 0\n",
    "    \n",
    "    # Force the image to be regenerated\n",
    "    force_gen = True\n",
    "    \n",
    "    return file.name\n",
    "    \n",
    "# Handles image saving\n",
    "def save_img():\n",
    "    global last_image\n",
    "    if not os.path.exists(\"saved_images\"):\n",
    "        os.mkdir(\"saved_images\")\n",
    "    filename = fr\"./saved_images/{time.ctime().replace(' ', '-').replace(':', '.')}.png\"\n",
    "    if type(last_image) is not PIL.Image.Image:\n",
    "        Image.fromarray(last_image.clip(0, 255).astype(np.uint8)).save(filename)\n",
    "    else:\n",
    "        last_image.save(filename)\n",
    "        \n",
    "# Function used to test the mouth movement\n",
    "def test_mouth():\n",
    "    global generating_mouth_movement\n",
    "    global m_thread\n",
    "    # Make sure the mouth isn't already moving\n",
    "    if generating_mouth_movement == True:\n",
    "        return\n",
    "    \n",
    "    # Make sure the thread is not running\n",
    "    if m_thread is not None:\n",
    "        m_thread.join()\n",
    "    \n",
    "    # Start the mouth movement loop\n",
    "    m_thread = threading.Thread(target=run_talk_loop, args=(\"test_audio.mp3\",))\n",
    "    m_thread.start()\n",
    "    \n",
    "\n",
    "interface = gr.Blocks()\n",
    "with interface:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Intro\"):\n",
    "            gr.Textbox(\"\"\"\n",
    "            Below is an intro explaining how this app works...\n",
    "            \n",
    "            Generation Tab:\n",
    "              Before starting, make sure to click the \"Setup interface\" button to\n",
    "              setup the inferface and to begin using the app.\n",
    "              \n",
    "              The upper-most part of the interface includes two tabs: \n",
    "              \"Voice-based Chat\" and \"Text-based Chat\" which are used\n",
    "              to repond to the AI. Voice-based allows you to use your\n",
    "              mic to talk to the AI while text-based allows you to\n",
    "              chat with the AI using text. The audio is auto-submitted\n",
    "              for response while the text requires either pressing the\n",
    "              \"enter\" key or clicking the \"Generate Audio\" button.\n",
    "              \n",
    "              The next part is the \"Response\" text field. The latest\n",
    "              response the AI gave will appear here.\n",
    "              \n",
    "              Below reponse is a section split into two parts. The left-most\n",
    "              part is the currently generated image. The rightmost section\n",
    "              has multiple parts:\n",
    "              1. \"Add motion to image?\" checkbox is used to toggle image\n",
    "                 animation. If checked, the image will be animated. The\n",
    "                 animation includes blinking and mouth movement assuming\n",
    "                 the image is in the correct form.\n",
    "              2. \"Mouth movement test\" can be used to check if mouth\n",
    "                 movement works for the current image.\n",
    "              3. \"Save current image\" saves the currently generated image\n",
    "                 to a folder named \"saved_images\". The filename will\n",
    "                 be the current time and date so that images don't\n",
    "                 overwrite eachother\n",
    "              4. \"Upload an image\" is used to upload an image you\n",
    "                 want to load in as opposed to generating one\n",
    "                 until one looks good. Clikcing on this button allows\n",
    "                 you to select the image you want to display.\n",
    "              \n",
    "              At the bottom of this section, there are two buttons:\n",
    "              \"Generate Audio\" and \"Generate Image\". \"Generate Audio\"\n",
    "              takes the currently entered text and generates a new\n",
    "              response from the AI. \"Generate Image\" is used to generate\n",
    "              a new image and display it.\n",
    "                 \n",
    "              Some notes about image animation:\n",
    "                The image must be in the correct form to be animated\n",
    "                correctly. The image should be a face-shot photo to\n",
    "                ensure that blinking is done correctly. Mouth movement\n",
    "                will occur if the image is face forward and when audio\n",
    "                is generated. Sometimes the mouth movement doesn't\n",
    "                work and if this is the case, you should probably\n",
    "                just generate an image until movement works.\n",
    "            \n",
    "            \n",
    "            Settings Tab:\n",
    "              The settings tab has several uses from loading in past memories\n",
    "              to changing the style of the image to generate.\n",
    "              \n",
    "              The first block in this tab is the \"Use custom chat model?\" checkbox.\n",
    "              If this box is checked, a free custom model will be used to\n",
    "              respond. Otherwise GPT-3 will respond. If the box is unchecked,\n",
    "              an OpenAI key is required which can obtained following this article:\n",
    "              https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0\n",
    "              If a key isn't provided, an error will be shown in place of\n",
    "              the response text.\n",
    "              \n",
    "              The next block is the \"Settings\" blocks which is used to setup\n",
    "              the style of the image and how it's generated. Settings can be\n",
    "              found at the following link (though do be warned, the site\n",
    "              has some sus images, not my doing btw):\n",
    "              https://danbooru.donmai.us/wiki_pages/tag_group:image_composition\n",
    "              \n",
    "              The next block is \"Characteristics\" which is also used to style\n",
    "              the generated images. These prompts are more of how you want the\n",
    "              generated image to look like. Should it be female or male?\n",
    "              What color hair?\n",
    "              \n",
    "              The \"settings\" block and \"characteristics\" block actually have no\n",
    "              difference when implemented, but it's nice to break up the\n",
    "              difference between image settings and image characteristics.\n",
    "              \n",
    "              The next block is the \"Guidance value\" which is used as a tradeoff\n",
    "              between Fidelity (how good the image looks) and variance (kind of how\n",
    "              creative the model is). A value of 1 is required, and having a\n",
    "              value too high will cause garbage to be produced. Keeping this\n",
    "              value around 10 seems to work well.\n",
    "              \n",
    "              The last part is a memory loading system. As the conversation goes on,\n",
    "              the conversation is saved to a memory file called \"config_file.json\". This\n",
    "              file can be loaded back in through this section of the settings to replace\n",
    "              the current conversation with a past one saved in a .json file.\n",
    "              ...\n",
    "              ...\n",
    "              ...\n",
    "              \n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.TabItem(\"Generation\"):\n",
    "            gen_col = gr.Column(visible=False)\n",
    "            with gen_col:\n",
    "                # Talking to the AI\n",
    "                with gr.Tabs():\n",
    "                    with gr.TabItem(\"Voice-based Chat\"):\n",
    "                        audio = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Response\", live=True)\n",
    "                    with gr.TabItem(\"Text-based Chat\"):\n",
    "                        text = gr.Textbox(label=\"Text\", value=\"I love you!\", interactive=True)\n",
    "                response = gr.Textbox(label=\"Response\", value=\"\", interactive=False)\n",
    "\n",
    "                with gr.Row():\n",
    "                    # Note gallery expects a 3-D array: (L, W, 3)\n",
    "                    gallery = gr.Image(label=\"Generated images\", show_label=False)\\\n",
    "                        .style(height=512)\n",
    "\n",
    "                    with gr.Column():\n",
    "                        # Switch to generate a new image with audio or keep the\n",
    "                        # image static\n",
    "                        motion_switch = gr.Checkbox(value=True, label=\"Add motion to image?\")\n",
    "                        motion_switch.change(fn=handle_motion_switch, inputs=[motion_switch], outputs=[])\n",
    "\n",
    "                        # Button to test mouth movement\n",
    "                        btn_mouth_test = gr.Button(\"Mouth movement test\")\n",
    "                        btn_mouth_test.click(fn=test_mouth, inputs=[], outputs=[])\n",
    "\n",
    "                        # Button to save the currently generated image\n",
    "                        btn_save_img = gr.Button(\"Save Current Image\")\n",
    "                        btn_save_img.click(fn=save_img, inputs=[], outputs=[])\n",
    "\n",
    "                        # Button to load an image\n",
    "                        upload_button = gr.UploadButton(\"Upload an image\", file_types=[\"image\"], file_count=\"single\")\n",
    "                        upload_button.upload(fn=upload_file, inputs=[upload_button])\n",
    "\n",
    "                with gr.Row():\n",
    "                    # Button to generate new audio\n",
    "                    btn_audio = gr.Button(\"Generate Audio\")\n",
    "\n",
    "                    # Button to generate new audio\n",
    "                    btn_img = gr.Button(\"Generate Image\")\n",
    "            \n",
    "            # Button to load and setup the generation tab\n",
    "            btn_load = gr.Button(\"Setup interface\")\n",
    "            btn_load.click(fn=event_loop, inputs=[], outputs=[gallery, gen_col, btn_load], queue=True)\n",
    "            \n",
    "            \n",
    "        with gr.TabItem(\"Settings\"):\n",
    "            # Switched for which model to use\n",
    "            custom_model = gr.Checkbox(value=True, label=\"Use custom chat model? (False to use GPT, True to use custom model)\")\n",
    "            GPT_key_ = gr.Textbox(label=\"Key to use GPT-3 (if using GPT-3)\\nNote: If you don't have one go here: https://elephas.app/blog/how-to-create-openai-api-keys-cl5c4f21d281431po7k8fgyol0\", value=\"\", interactive=True)\n",
    "            custom_audio = gr.Checkbox(value=False, label=\"Use custom audio model?\")\n",
    "\n",
    "            # Settings for the image\n",
    "            settings = gr.Textbox(label=\"Settings\", value= \"1girl,solo focus,very wide shot,feamle focus,ratio:16:9,detailed,looking at viewer,facing viewer,facing forward,vtuber\", interactive=True)\n",
    "            characteristics = gr.Textbox(label=\"Characteristics\", value=\"waifu,female,brown hair,blue eyes,sidelocks,slight blush,happy\", interactive=True)\n",
    "            guidance_scale = gr.Number(label=\"Guidance value - Tradeoff between creativity and image fidelity (greater than 1.0)\", value=10.0, interactive=True, precision=1)\n",
    "            \n",
    "            # Used to load a memory file\n",
    "            with gr.Column():\n",
    "                mem_file = gr.Textbox(label=\"Memory File\", value= \"\", interactive=True)\n",
    "                with gr.Row():\n",
    "                    mem_load_btn = gr.Button(\"Load memory file\")\n",
    "                    mem_file_success = gr.Textbox(label=\"Was the load successful?\", value= \"\", interactive=False)\n",
    "                    mem_load_btn.click(fn=load_mem, inputs=[mem_file], outputs=[mem_file_success])\n",
    "            \n",
    "        # When the audio is changed, we want to auto submit it\n",
    "        audio.change(fn=audio_auto_submit, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        \n",
    "        # When the button or text is submitted, we want to generate new audio\n",
    "        btn_audio.click(fn=generate_audio, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        text.submit(fn=generate_audio, inputs=[custom_audio, custom_model, text, audio, GPT_key_], outputs=[response])\n",
    "        \n",
    "        # When the image button is clicked, we want to generate a new image\n",
    "        btn_img.click(fn=generate_img, inputs=[settings, characteristics, guidance_scale], outputs=[])\n",
    "\n",
    "interface.queue(concurrency_count=2).launch(debug=True, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75e742-9533-468e-b497-504d0bcd0b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec25b5-3884-45a0-a1a2-5556684ad90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
