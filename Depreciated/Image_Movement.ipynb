{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef67e7fb-530f-4d67-8bdf-953c281206f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://github.com/topics/vtuber\\n1. https://github.com/1996scarlet/OpenVtuber\\n2. https://github.com/1996scarlet/faster-mobile-retinaface \\n   (faster version of 1)\\n3. https://github.com/pkhungurn/talking-head-anime-demo \\n   (may be slow and bg needs to be removed)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possible sources:\n",
    "\"\"\"\n",
    "https://github.com/topics/vtuber\n",
    "1. https://github.com/1996scarlet/OpenVtuber\n",
    "2. https://github.com/1996scarlet/faster-mobile-retinaface \n",
    "   (faster version of 1)\n",
    "3. https://github.com/pkhungurn/talking-head-anime-demo \n",
    "   (may be slow and bg needs to be removed)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0443c1-c54f-4668-b3df-b55cb25d80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from Talking_Head.Talking_Head import Talking_Head\n",
    "from putting_it_together import blink_loop\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess\n",
    "import gradio as gr\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db68e9a-14f3-4031-bf02-a8952c2aece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db610950-5739-4e5a-a47e-d94b77d0ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the image\n",
    "global img\n",
    "img = Image.open(\"test5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63735be4-17b2-4cf9-975b-3825337ce911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ba214-194d-44e2-a5b5-8ddd08d2838e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956bdf97-e659-49f0-b787-8a48b757f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio live image loop documentation:\n",
    "# https://github.com/gradio-app/gradio/pull/2189\n",
    "\n",
    "def blink_loop():\n",
    "    global img\n",
    "    # Initialize the Talking Head class to add movement to images\n",
    "    img_anim = Talking_Head(torch.device(\"cuda:0\"), 0.6, automatic_EMA=False)\n",
    "\n",
    "    # Load in the new image\n",
    "    img_anim.load_new_image(img=deepcopy(img))\n",
    "    \n",
    "    # Start the initial timer\n",
    "    update_timer_start = time.time()\n",
    "\n",
    "    # Default pose\n",
    "    img = img_anim.change_pose()\n",
    "    \n",
    "    while True:\n",
    "        # Wait a little to blink again\n",
    "        if img_anim.cycle_end:\n",
    "            # time this function so that it doesn't\n",
    "            # add to the EMA\n",
    "            pause_time_start = time.time()\n",
    "            \n",
    "            # Blink anywhere between 2 and 7 secods with\n",
    "            # a mean around 5 seconds (avg blink wait time)\n",
    "            t = np.clip(np.random.normal(5, 1, size=1)[0], 2, 7)\n",
    "\n",
    "            plt.pause(t)\n",
    "            img_anim.cycle_end = False\n",
    "            \n",
    "            # Get the pause time\n",
    "            pause_time = pause_time_start-time.time()\n",
    "            \n",
    "            # Update the initial time with the pause time\n",
    "            update_timer_start -= pause_time\n",
    "        \n",
    "        # Update the vector\n",
    "        img_anim.Move_eyes()\n",
    "        \n",
    "        # Change the pose\n",
    "        img = img_anim.change_pose()\n",
    "        \n",
    "        # Get the ending time for the loop\n",
    "        display_time = time.time()-update_timer_start\n",
    "        \n",
    "        # Update the EMA\n",
    "        img_anim.update_EMA(display_time)\n",
    "        \n",
    "        # Start the timer to see how long it takes\n",
    "        # to display the image and generate a new one\n",
    "        update_timer_start = time.time()\n",
    "        \n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7f1bff-8da1-4f94-adc1-bd75e9e96423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fake_diffusion():\n",
    "    for i in range(100):\n",
    "        time.sleep(1)\n",
    "        yield np.random.random((200, 200, 3))\n",
    "\n",
    "        \n",
    "        \n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        \n",
    "        btn = gr.Button()\n",
    "        image = gr.Image().style(height=330)\n",
    "        btn.click(fake_diffusion, inputs=[], outputs=[image])\n",
    "\n",
    "demo.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33dd1129-3580-4c84-970e-060a54dbb894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 337, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 847, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\gradio\\utils.py\", line 410, in async_iteration\n",
      "    return next(iterator)\n",
      "  File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_85176\\449470762.py\", line 16, in blink_loop\n",
      "    img = img_anim.change_pose()\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\Talking_Head.py\", line 225, in change_pose\n",
      "    output_image = self.poser.pose(self.torch_input_image, self.pose)[0]\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\tha2\\poser\\general_poser_02.py\", line 62, in pose\n",
      "    output_list = self.get_posing_outputs(image, pose)\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\tha2\\poser\\general_poser_02.py\", line 66, in get_posing_outputs\n",
      "    modules = self.get_modules()\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\tha2\\poser\\general_poser_02.py\", line 44, in get_modules\n",
      "    module = self.module_loaders[key]()\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\tha2\\poser\\modes\\mode_20.py\", line 327, in <lambda>\n",
      "    lambda: load_face_morpher(module_file_names[KEY_FACE_MORPHER]),\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\tha2\\poser\\modes\\mode_20.py\", line 220, in load_face_morpher\n",
      "    module.load_state_dict(torch_load(file_name))\n",
      "  File \"D:\\AI Stuff\\MyWaifu\\Talking_Head\\tha2\\util.py\", line 23, in torch_load\n",
      "    with open(file_name, 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../Talking_Head/data/face_morpher.pt'\n"
     ]
    }
   ],
   "source": [
    "def fake_diffusion(steps):\n",
    "    for i in range(steps):\n",
    "        time.sleep(1)\n",
    "        yield np.random.random((200, 200, 3))\n",
    "\n",
    "io = gr.Interface(blink_loop, inputs=[], outputs=[gr.Image().style(height=330)])\n",
    "io.queue().launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35836f92-6c6e-47b2-8a88-357a87ee1ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
